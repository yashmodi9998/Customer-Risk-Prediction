{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_21812\\4097840662.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Z_CARD_ART'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_21812\\4097840662.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Z_LAST_NAME'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('risk-train.txt', delimiter='\\t')  \n",
    "\n",
    "# Replace missing values (represented by '?') with NaN\n",
    "df.replace('?', pd.NA, inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "df.dropna(subset=['ORDER_ID', 'CLASS'], inplace=True)\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "date_columns = ['B_BIRTHDATE', 'DATE_LORDER']\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# Feature engineering on date columns\n",
    "# Convert B_BIRTHDATE to age and DATE_LORDER to days since last order\n",
    "df['AGE'] = df['B_BIRTHDATE'].apply(lambda x: (dt.datetime.now() - x).days // 365 if pd.notna(x) else 0)\n",
    "df['DAYS_SINCE_LAST_ORDER'] = df['DATE_LORDER'].apply(lambda x: (dt.datetime.now() - x).days if pd.notna(x) else 0)\n",
    "\n",
    "# Fill missing numerical values with 0 \n",
    "numerical_columns = ['VALUE_ORDER', 'AMOUNT_ORDER', 'AMOUNT_ORDER_PRE', 'VALUE_ORDER_PRE', 'TIME_ORDER', 'AGE', 'DAYS_SINCE_LAST_ORDER', 'MAHN_AKT', 'MAHN_HOECHST']\n",
    "df[numerical_columns] = df[numerical_columns].fillna(0)\n",
    "\n",
    "# Fill missing values with unknown\n",
    "df['Z_CARD_ART'].fillna('Unknown', inplace=True)\n",
    "df['Z_LAST_NAME'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "drop_columns = ['ANUMMER_01', 'ANUMMER_02', 'ANUMMER_03', 'ANUMMER_04', 'ANUMMER_05', 'ANUMMER_06', 'ANUMMER_07', 'ANUMMER_08', 'ANUMMER_09', 'ANUMMER_10', 'B_BIRTHDATE', 'DATE_LORDER']\n",
    "df.drop(columns=drop_columns, inplace=True)\n",
    "\n",
    "# Convert binary columns to boolean (using 1 and 0)\n",
    "df['B_EMAIL'] = df['B_EMAIL'].map({'yes': 1, 'no': 0})\n",
    "df['B_TELEFON'] = df['B_TELEFON'].map({'yes': 1, 'no': 0})\n",
    "df['FLAG_LRIDENTISCH'] = df['FLAG_LRIDENTISCH'].map({'yes': 1, 'no': 0})\n",
    "df['FLAG_NEWSLETTER'] = df['FLAG_NEWSLETTER'].map({'yes': 1, 'no': 0})\n",
    "df['CHK_LADR'] = df['CHK_LADR'].map({'yes': 1, 'no': 0})\n",
    "df['CHK_RADR'] = df['CHK_RADR'].map({'yes': 1, 'no': 0})\n",
    "df['CHK_KTO'] = df['CHK_KTO'].map({'yes': 1, 'no': 0})\n",
    "df['CHK_COOKIE'] = df['CHK_COOKIE'].map({'yes': 1, 'no': 0})\n",
    "df['CHK_CARD'] = df['CHK_CARD'].map({'yes': 1, 'no': 0})\n",
    "df['CHK_IP'] = df['CHK_IP'].map({'yes': 1, 'no': 0})\n",
    "df['FAIL_LPLZ'] = df['FAIL_LPLZ'].map({'yes': 1, 'no': 0})\n",
    "df['FAIL_LORT'] = df['FAIL_LORT'].map({'yes': 1, 'no': 0})\n",
    "df['FAIL_LPLZORTMATCH'] = df['FAIL_LPLZORTMATCH'].map({'yes': 1, 'no': 0})\n",
    "df['FAIL_RPLZ'] = df['FAIL_RPLZ'].map({'yes': 1, 'no': 0})\n",
    "df['FAIL_RORT'] = df['FAIL_RORT'].map({'yes': 1, 'no': 0})\n",
    "df['FAIL_RPLZORTMATCH'] = df['FAIL_RPLZORTMATCH'].map({'yes': 1, 'no': 0})\n",
    "df['NEUKUNDE'] = df['NEUKUNDE'].map({'yes': 1, 'no': 0})\n",
    "df['CLASS'] = df['CLASS'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Separate the target variable \n",
    "dep_var = df['CLASS']\n",
    "\n",
    "# Drop the target column from the main data\n",
    "indp_var = df.drop(columns=['CLASS'])\n",
    "\n",
    "# Perform one-hot encoding on the remaining features\n",
    "indp_var = pd.get_dummies(indp_var, prefix=None, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TN = confusion_matrix[0,0]\n",
    "# FP = confusion_matrix[0,1]\n",
    "# FN = confusion_matrix[1,0]\n",
    "# TP = confusion_matrix[1,1]\n",
    "\n",
    "def custom_precision(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    TP = cm[1, 1]  # True Positives\n",
    "    FP = cm[0, 1]  # False Positives\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    return precision\n",
    "\n",
    "def custom_recall(y_true, y_pred):\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Calculate True Positives and False Negatives\n",
    "    TP = cm[1, 1]  # True Positives (actual high-risk correctly predicted as high-risk)\n",
    "    FN = cm[1, 0]  # False Negatives (actual high-risk incorrectly predicted as low-risk)\n",
    "    \n",
    "    # Calculate Recall\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    return recall\n",
    "\n",
    "def custom_f1_score(y_true, y_pred):\n",
    "    precision = custom_precision(y_true, y_pred) * 100\n",
    "    recall = custom_recall(y_true, y_pred) * 100\n",
    "    f1_score = 2 * ((precision * recall) / (precision + recall)) if (precision + recall) > 0 else 0\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Define cost-sensitive metric function as you have it\n",
    "def cost_sensitive_metric(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix \\n\", cm)\n",
    "    FN = cm[1, 0]\n",
    "    FP = cm[0, 1]\n",
    "    \n",
    "    # Applying the given cost matrix\n",
    "    cost = (FN * 50) + (FP * 5)\n",
    "    return cost\n",
    "\n",
    "class CostSensitiveDecisionTree(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, max_depth=15, min_samples_split=3, threshold=0.5, random_state=42):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.threshold = threshold\n",
    "        self.tree = DecisionTreeClassifier(max_depth=self.max_depth, min_samples_split=self.min_samples_split, class_weight={0: 1, 1: 17}, random_state=random_state)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Fit the internal decision tree model\n",
    "        self.tree.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict probabilities and apply threshold for cost-sensitivity\n",
    "        raw_preds = self.tree.predict_proba(X)[:, 1]\n",
    "        return np.where(raw_preds > self.threshold, 1, 0)  # Threshold is set at 0.5\n",
    "\n",
    "    def recall(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return custom_recall(y, y_pred)\n",
    "    \n",
    "    def precision(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return custom_precision(y, y_pred)\n",
    "    \n",
    "    def f1_score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return custom_f1_score(y, y_pred)\n",
    "    \n",
    "    def cost_metric(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return cost_sensitive_metric(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "Confusion Matrix \n",
      " [[18765  3838]\n",
      " [  673   724]]\n",
      "Cost on training data: 52840\n",
      "recall on training data: 51.83 %\n",
      "\n",
      "Testing Data:\n",
      "Confusion Matrix \n",
      " [[4692  959]\n",
      " [ 164  185]]\n",
      "Cost on testing data: 12995\n",
      "recall on testing data: 53.01 %\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(indp_var, dep_var, test_size=0.2, random_state=42, stratify=dep_var)\n",
    "\n",
    "# Instantiate the model with desired hyperparameters\n",
    "model = CostSensitiveDecisionTree(max_depth=5, min_samples_split=10, threshold=0.66, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "recall_train = model.recall(x_train,y_train)\n",
    "recall_test = model.recall(x_test, y_test)\n",
    "\n",
    "print(\"Training Data:\")\n",
    "cost_train = model.cost_metric(x_train,y_train)\n",
    "print(f\"Cost on training data: {cost_train}\")\n",
    "print(f\"recall on training data: {recall_train*100:.2f} %\")\n",
    "\n",
    "\n",
    "print(\"\\nTesting Data:\")\n",
    "cost_test = model.cost_metric(x_test, y_test)\n",
    "print(f\"Cost on testing data: {cost_test}\")\n",
    "print(f\"recall on testing data: {recall_test*100:.2f} %\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
